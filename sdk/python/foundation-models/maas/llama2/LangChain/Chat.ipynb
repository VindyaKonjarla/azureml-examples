{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AzureMLEndpointApiType"
      ],
      "metadata": {},
      "id": "ae5516cb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "•It determines the communication protocol and format used to send and receive data between clients and the deployed model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "2309a3df-497f-4aa9-ab9b-7d25ad176914"
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {},
      "id": "29fa59e9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {},
      "id": "21df9ccb"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models.azureml_endpoint import AzureMLChatOnlineEndpoint\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain_community.chat_models.azureml_endpoint import AzureMLChatOnlineEndpoint\n",
        "from langchain.schema import HumanMessage\n",
        "from langchain.schema import HumanMessage\n",
        "from dotenv import dotenv_values\n",
        "from langchain_community.chat_models.azureml_endpoint import (\n",
        "    AzureMLEndpointApiType,\n",
        "    LlamaChatContentFormatter,"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "ac9f29e7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "•dotenv_values():It allows you to read key-value pairs from a .env file and return them as a dictionary\n",
        "\n",
        "•.env: It is an environment file where the API key and model URL are stored.The environment file should be in the same root directory."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "0c4dd9de-fe16-4283-9f79-ca499a67d16f"
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {},
      "id": "18986ad0"
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {},
      "id": "8c3da83d"
    },
    {
      "cell_type": "code",
      "source": [
        "config = dotenv_values(\".env\")\n",
        "config1=dict(config)  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "68ab4302"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AzureMLChatOnlineEndpoint"
      ],
      "metadata": {},
      "id": "cd960cd5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "•\tIt provides functionalities to send text prompts to the model and receive its responses.\n",
        "\n",
        "•\t.endpoint_url: This specifies the URL of the deployed chat model endpoint located on your Azure Machine Learning service. You likely found this in your config1 dictionary under the key \"BASE_URL\".\n",
        "\n",
        "\t\n",
        "•\tendpoint_api_type: This sets the type of API used by the endpoint. Here, AzureMLEndpointApiType.serverless indicates you're using a serverless deployment on Azure Functions.\n",
        "\n",
        "•\tendpoint_api_key: This provides the necessary authorization key to access the endpoint. You probably got this from config1[\"API_KEY\"].\n",
        "\n",
        "•\tcontent_formatter: This defines how input and output data are formatted for the chat model. You're using LlamaChatContentFormatter(), which is specifically designed for LLaMa2-chat models.\n",
        "\n",
        "•\tmodel_kwargs: This is a dictionary of additional arguments passed to the model:\n",
        "\n",
        "•\ttemperature: This controls the randomness of the generated text. Here, it's set to 0.8, favoring higher creativity but potentially less coherence.\n",
        "\n",
        "•\tmax_new_tokens: This limits the maximum number of new tokens (words) the model can generate in its response, set to 400 in this case."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "b9a98d4c-2613-4137-82c4-91a6a927fe2a"
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {},
      "id": "1c777bc4"
    },
    {
      "cell_type": "code",
      "source": [
        "chat = AzureMLChatOnlineEndpoint(\n",
        "    endpoint_url=config1[\"BASE_URL\"], \n",
        "    endpoint_api_type=AzureMLEndpointApiType.serverless,\n",
        "    endpoint_api_key=config1[\"API_KEY\"],\n",
        "    content_formatter=LlamaChatContentFormatter(),\n",
        "    model_kwargs={\"temperature\": 0.8}, \n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "40c1dd98"
    },
    {
      "cell_type": "markdown",
      "source": [
        "•chat.invoke(): This method sends the provided message(s) to the LLM and retrieves its response."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "id": "ae1e98a0-2325-4ad1-ac2b-f158b227227a"
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {},
      "id": "2c98e305"
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.invoke(\n",
        "    [HumanMessage(content=\"Will the Collatz conjecture ever be solved?\")],\n",
        "    max_tokens=512,\n",
        ")\n",
        "response"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {},
      "id": "a0bdcbb0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
